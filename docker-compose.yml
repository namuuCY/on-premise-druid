#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
version: "2.2"

# 컨테이너간 볼륨 공유를 위해 volume을 최상위에 선언
volumes:
  metadata_data: { }
  middle_var: { }
  historical_var: { }
  broker_var: { }
  coordinator_var: { }
  router_var: { }
  druid_shared: { }
  overlord_var: { }
  zookeeper1-data: { }
  zookeeper2-data: { }
  zookeeper3-data: { }
  journalnode1-data: { }
  journalnode2-data: { }
  journalnode3-data: { }
  namenode1-data:
  namenode2-data:
  datanode1-data:
  datanode2-data:


services:
  spring-boot:
    build: .
    restart: always
    container_name: spring-boot
    ports:
      - 8080:8080

  zookeeper1:
    image: zookeeper:3.5.10
    restart: always
    container_name: zookeeper1
    environment:
      CLUSTER_NAME: mycluster
      ALLOW_ANONYMOUS_LOGIN: yes
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=zookeeper1:2888:3888;2181 server.2=zookeeper2:2888:3888;2181 server.3=zookeeper3:2888:3888;2181
    ports:
      - "2181:2181"
    expose:
      - "2888"
      - "3888"
    volumes:
      - zookeeper1-data:/druid/zookeeper
      - ./hadoop-conf/core-site.xml:/opt/hadoop-3.2.1/etc/hadoop/core-site.xml
      - ./hadoop-conf/hdfs-site.xml:/opt/hadoop-3.2.1/etc/hadoop/hdfs-site.xml

  zookeeper2:
    image: zookeeper:3.5.10
    restart: always
    container_name: zookeeper2
    environment:
      CLUSTER_NAME: mycluster
      ALLOW_ANONYMOUS_LOGIN: yes
      ZOO_MY_ID: 2
      ZOO_SERVERS: server.1=zookeeper1:2888:3888;2181 server.2=zookeeper2:2888:3888;2181 server.3=zookeeper3:2888:3888;2181
    ports:
      - "2182:2181"
    expose:
      - "2888"
      - "3888"
    volumes:
      - zookeeper2-data:/druid/zookeeper
      - ./hadoop-conf/core-site.xml:/opt/hadoop-3.2.1/etc/hadoop/core-site.xml
      - ./hadoop-conf/hdfs-site.xml:/opt/hadoop-3.2.1/etc/hadoop/hdfs-site.xml

  zookeeper3:
    image: zookeeper:3.5.10
    container_name: zookeeper3
    environment:
      CLUSTER_NAME: mycluster
      ALLOW_ANONYMOUS_LOGIN: yes
      ZOO_MY_ID: 3
      ZOO_SERVERS: server.1=zookeeper1:2888:3888;2181 server.2=zookeeper2:2888:3888;2181 server.3=zookeeper3:2888:3888;2181
    ports:
      - "2183:2181"
    expose:
      - "2888"
      - "3888"
    volumes:
      - zookeeper3-data:/druid/zookeeper
      - ./hadoop-conf/core-site.xml:/opt/hadoop-3.2.1/etc/hadoop/core-site.xml
      - ./hadoop-conf/hdfs-site.xml:/opt/hadoop-3.2.1/etc/hadoop/hdfs-site.xml

  zookeeper-navigator:
    hostname: zookeeper-navigator
    container_name: zookeeper-navigator
    image: elkozmon/zoonavigator:1.1.2
    restart: always
    ports:
      - 9000:9000
    environment:
      HTTP_PORT: 9000
      ALLOW_ANONYMOUS_LOGIN: yes
    depends_on:
      - zookeeper1
      - zookeeper2
      - zookeeper3

  journalnode1:
    image: makengi12/journalnode:1.0
    container_name: journalnode1
    environment:
      - CLUSTER_NAME=mycluster
    volumes:
      - journalnode1-data:/hadoop/dfs/journal
      - ./hadoop-conf/core-site.xml:/opt/hadoop-3.2.1/etc/hadoop/core-site.xml
      - ./hadoop-conf/hdfs-site.xml:/opt/hadoop-3.2.1/etc/hadoop/hdfs-site.xml
    expose:
      - "8485"
    depends_on:
      - zookeeper1
      - zookeeper2
      - zookeeper3

  journalnode2:
    image: makengi12/journalnode:1.0
    container_name: journalnode2
    environment:
      - CLUSTER_NAME=mycluster
    volumes:
      - journalnode2-data:/hadoop/dfs/journal
      - ./hadoop-conf/core-site.xml:/opt/hadoop-3.2.1/etc/hadoop/core-site.xml
      - ./hadoop-conf/hdfs-site.xml:/opt/hadoop-3.2.1/etc/hadoop/hdfs-site.xml
    expose:
      - "8485"
    depends_on:
      - zookeeper1
      - zookeeper2
      - zookeeper3

  journalnode3:
    image: makengi12/journalnode:1.0
    container_name: journalnode3
    environment:
      - CLUSTER_NAME=mycluster
    volumes:
      - journalnode3-data:/hadoop/dfs/journal
      - ./hadoop-conf/core-site.xml:/opt/hadoop-3.2.1/etc/hadoop/core-site.xml
      - ./hadoop-conf/hdfs-site.xml:/opt/hadoop-3.2.1/etc/hadoop/hdfs-site.xml
    expose:
      - "8485"
    depends_on:
      - zookeeper1
      - zookeeper2
      - zookeeper3

  namenode1:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode1
    environment:
      - DFS_NAMENODE_SHARED_EDITS_DIR=qjournal://journalnode1:8485;journalnode2:8485;journalnode3:8485/mycluster
      - NAMENODE_ID=namenode1
      - CLUSTER_NAME=mycluster
    ports:
      - "8020:8020"
      - "9870:9870"
    volumes:
      - namenode1-data:/hadoop/dfs/name
      - ./hadoop-conf/core-site.xml:/opt/hadoop-3.2.1/etc/hadoop/core-site.xml
      - ./hadoop-conf/hdfs-site.xml:/opt/hadoop-3.2.1/etc/hadoop/hdfs-site.xml
    depends_on:
      - journalnode1
      - journalnode2
      - journalnode3
      - zookeeper1
      - zookeeper2
      - zookeeper3

  namenode2:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode2
    environment:
      - DFS_NAMENODE_SHARED_EDITS_DIR=qjournal://journalnode1:8485;journalnode2:8485;journalnode3:8485/mycluster
      - NAMENODE_ID=namenode2
      - CLUSTER_NAME=mycluster
    expose:
      - "8020"
      - "9870"
    volumes:
      - namenode2-data:/hadoop/dfs/name
      - ./hadoop-conf/core-site.xml:/opt/hadoop-3.2.1/etc/hadoop/core-site.xml
      - ./hadoop-conf/hdfs-site.xml:/opt/hadoop-3.2.1/etc/hadoop/hdfs-site.xml
    depends_on:
      - journalnode1
      - journalnode2
      - journalnode3
      - zookeeper1
      - zookeeper2
      - zookeeper3

  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode1
    environment:
      - CLUSTER_NAME=mycluster
      - CORE_CONF_fs_defaultFS=mycluster
    volumes:
      - datanode1-data:/hadoop/dfs/data
      - ./hadoop-conf/core-site.xml:/opt/hadoop-3.2.1/etc/hadoop/core-site.xml
      - ./hadoop-conf/hdfs-site.xml:/opt/hadoop-3.2.1/etc/hadoop/hdfs-site.xml
    depends_on:
      - namenode1
      - namenode2

  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode2
    environment:
      - CLUSTER_NAME=mycluster
      - CORE_CONF_fs_defaultFS=mycluster
    volumes:
      - datanode2-data:/hadoop/dfs/data
      - ./hadoop-conf/core-site.xml:/opt/hadoop-3.2.1/etc/hadoop/core-site.xml
      - ./hadoop-conf/hdfs-site.xml:/opt/hadoop-3.2.1/etc/hadoop/hdfs-site.xml
    depends_on:
      - namenode1
      - namenode2

  postgres:
    container_name: postgres
    image: postgres:latest
    ports:
      - "5432:5432"
    volumes:
      - metadata_data:/var/lib/postgresql/data
    env_file:
      - .env

  # 모두 같은 docker image를 사용, 이를 command로 컨테이너 별 서비스 역할 분리
  coordinator:
    image: apache/druid:32.0.0
    container_name: coordinator
    volumes:
      - druid_shared:/opt/shared
      - coordinator_var:/opt/druid/var
      - ./hadoop-conf:/opt/hadoop/conf
      - ./raw-data.csv:/opt/druid/raw-data.csv
    depends_on:
      - zookeeper1
      - postgres
    ports:
      - "8081:8081"
    command:
      - coordinator
    env_file:
      - .env

  coordinator2:
    image: apache/druid:32.0.0
    container_name: coordinator2
    volumes:
      - druid_shared:/opt/shared
      - coordinator_var:/opt/druid/var
      - ./hadoop-conf:/opt/hadoop/conf
      - ./raw-data.csv:/opt/druid/raw-data.csv
    depends_on:
      - zookeeper1
      - postgres
    ports:
      - "9081:8081"
    command:
      - coordinator
    env_file:
      - .env

  broker:
    image: apache/druid:32.0.0
    container_name: broker
    volumes:
      - broker_var:/opt/druid/var
      - ./hadoop-conf:/opt/hadoop/conf
      - ./raw-data.csv:/opt/druid/raw-data.csv
    depends_on:
      - zookeeper1
      - postgres
      - coordinator
    ports:
      - "8082:8082"
    command:
      - broker
    env_file:
      - .env

  historical:
    image: apache/druid:32.0.0
    container_name: historical
    volumes:
      - druid_shared:/opt/shared
      - historical_var:/opt/druid/var
      - ./hadoop-conf:/opt/hadoop/conf
      - ./raw-data.csv:/opt/druid/raw-data.csv
    depends_on:
      - zookeeper1
      - postgres
      - coordinator
    ports:
      - "8083:8083"
    command:
      - historical
    env_file:
      - .env

  middlemanager:
    image: apache/druid:32.0.0
    container_name: middlemanager
    volumes:
      - druid_shared:/opt/shared
      - middle_var:/opt/druid/var
      - ./hadoop-conf:/opt/hadoop/conf
      - ./raw-data.csv:/opt/druid/raw-data.csv
    depends_on:
      - zookeeper1
      - postgres
      - coordinator
    ports:
      - "8091:8091"
      - "8100-8105:8100-8105"
    command:
      - middleManager
    env_file:
      - .env

  router:
    image: apache/druid:32.0.0
    container_name: router
    volumes:
      - router_var:/opt/druid/var
      - ./hadoop-conf:/opt/hadoop/conf
      - ./raw-data.csv:/opt/druid/raw-data.csv
    depends_on:
      - zookeeper1
      - postgres
      - coordinator
    ports:
      - "8888:8888"
    command:
      - router
    env_file:
      - .env

  overlord:
    image: apache/druid:32.0.0
    container_name: overlord
    volumes:
      - druid_shared:/opt/shared
      - overlord_var:/opt/druid/var
      - ./hadoop-conf:/opt/hadoop/conf
      - ./raw-data.csv:/opt/druid/raw-data.csv
    depends_on:
      - zookeeper1
      - postgres
      - coordinator
    ports:
      - "8090:8090"
    command:
      - overlord
    env_file:
      - .env
